---
title: "Natural Language Processing Milestone Report"
author: "Scott Arendt"
date: "April 29, 2016"
output: html_document
---

### Natural Language Processing Project

Hello.  Welcome to my milestone report.  So far, I have found this project to be interesting.  When describing the project to my friends, I can point out that their smart phones use natural language processing when they write out a text.  It is interesting to understand some of the steps that would be involved in making my smart phone predict the next word of my text.

It is also intimidating.  I could see myself working on this project full time for the next year and still adding improvements.


### Analysis of the Dataset

We are working with the Corpora provided by Hans Christensen (http://www.corpora.heliohost.org/index.html).  Specifically, I  am using the US English set of files.

Christensen has been collecting Corpora data from the Internet, using blogs, news sites and tweets as his sources.  Here are the summaries of the files that I am using.

Blogs
38,050,950 words
899,289 lines

News 
35,628,125 words
1,010,243 lines

Twitter
31,062,690 words
2,360,149 lines

### Including Plots

Has the data scientist made basic plots, such as histograms to illustrate features of the data?

Before I started processing the raw data, I used sampling to divide the data into training, test and validation sets. Much of my 

Start slapping in the 1000/5000/10000/50000/100000 counts

```{r sampleanalysis, echo=FALSE}
library(ggplot2)
myCorpusData <- data.frame(source=character(0), lineCount=integer(0), nGram= character(0), count= integer(0), stringsAsFactors = FALSE)
newrow1000 = cbind("Twitter", 1000, "Unigram", 3326)
newrow5000 = cbind("Twitter", 5000, "Unigram", 9917)
newrow10000 = cbind("Twitter", 10000, "Unigram", 15607)
newrow50000 = cbind("Twitter", 50000, "Unigram", 42514)
newrow100000 = cbind("Twitter", 100000, "Unigram", 65520)
myCorpusData <- rbind(myCorpusData,newrow1000,newrow5000,newrow10000,newrow50000,newrow100000)
newrow1000 = cbind("Twitter", 1000, "Bigram", 6316)
newrow5000 = cbind("Twitter", 5000, "Bigram", 29679)
newrow10000 = cbind("Twitter", 10000, "Bigram", 57363)
newrow50000 = cbind("Twitter", 50000, "Bigram", 254469)
newrow100000 = cbind("Twitter", 100000, "Bigram", 472413)
myCorpusData <- rbind(myCorpusData,newrow1000,newrow5000,newrow10000,newrow50000,newrow100000)
newrow1000 = cbind("Twitter", 1000, "Trigram", 5523)
newrow5000 = cbind("Twitter", 5000, "Trigram", 27266)
newrow10000 = cbind("Twitter", 10000, "Trigram", 54416)
newrow50000 = cbind("Twitter", 50000, "Trigram", 270274)
newrow100000 = cbind("Twitter", 100000, "Trigram", 535322)
myCorpusData <- rbind(myCorpusData,newrow1000,newrow5000,newrow10000,newrow50000,newrow100000)
newrow1000 = cbind("News", 1000, "Unigram", 7897)
newrow5000 = cbind("News", 5000, "Unigram", 22026)
newrow10000 = cbind("News", 10000, "Unigram", 32454)
newrow50000 = cbind("News", 50000, "Unigram", 76906)
newrow100000 = cbind("News", 100000, "Unigram", 96481)
myCorpusData <- rbind(myCorpusData,newrow1000,newrow5000,newrow10000,newrow50000,newrow100000)
newrow1000 = cbind("News", 1000, "Bigram", 18321)
newrow5000 = cbind("News", 5000, "Bigram", 89441)
newrow10000 = cbind("News", 10000, "Bigram", 173144)
newrow50000 = cbind("News", 50000, "Bigram", 757572)
newrow100000 = cbind("News", 100000, "Bigram", 1115641)
myCorpusData <- rbind(myCorpusData,newrow1000,newrow5000,newrow10000,newrow50000,newrow100000)
newrow1000 = cbind("News", 1000, "Trigram", 17908)
newrow5000 = cbind("News", 5000, "Trigram", 91261)
newrow10000 = cbind("News", 10000, "Trigram", 182579)
newrow50000 = cbind("News", 50000, "Trigram", 894034)
newrow100000 = cbind("News", 100000, "Trigram", 1372243)
myCorpusData <- rbind(myCorpusData,newrow1000,newrow5000,newrow10000,newrow50000,newrow100000)
newrow1000 = cbind("Blogs", 1000, "Unigram", 7895)
newrow5000 = cbind("Blogs", 5000, "Unigram", 21641)
newrow10000 = cbind("Blogs", 10000, "Unigram", 32012)
newrow50000 = cbind("Blogs", 50000, "Unigram", 79076)
newrow100000 = cbind("Blogs", 100000, "Unigram", 117053)
myCorpusData <- rbind(myCorpusData,newrow1000,newrow5000,newrow10000,newrow50000,newrow100000)
newrow1000 = cbind("Blogs", 1000, "Bigram", 20267)
newrow5000 = cbind("Blogs", 5000, "Bigram", 95517)
newrow10000 = cbind("Blogs", 10000, "Bigram", 184202)
newrow50000 = cbind("Blogs", 50000, "Bigram", 812890)
newrow100000 = cbind("Blogs", 100000, "Bigram", 1503204)
myCorpusData <- rbind(myCorpusData,newrow1000,newrow5000,newrow10000,newrow50000,newrow100000)
newrow1000 = cbind("Blogs", 1000, "Trigram", 20015)
newrow5000 = cbind("Blogs", 5000, "Trigram", 98702)
newrow10000 = cbind("Blogs", 10000, "Trigram", 196419)
newrow50000 = cbind("Blogs", 50000, "Trigram", 976388)
newrow100000 = cbind("Blogs", 100000, "Trigram", 1939260)
myCorpusData <- rbind(myCorpusData,newrow1000,newrow5000,newrow10000,newrow50000,newrow100000)

colnames(myCorpusData) <- c("Source", "Sample Size", "nGram", "Token Count")


ggplot(myCorpusData, aes(x="Sample Size", y="Token Count", fill="Source", alpha="nGram")) +
  geom_bar(stat="identity", width=0.5)

ggplot(myCorpusData, aes(x="Sample Size", y="Token Count"), fill="Source") +
  geom_bar(stat="identity", width=0.5)


group=interaction(treatment, replicate)

```

What did I do to process the data?

Numbers
lowercase

### Prediction Algorithm

I have not finalized the method that I am going to be using for my prediction algorithm.  I am leaning toward a method of weighting the prediction almost solely on frequency counts of the nGrams. 

Now that I am comfortable that my corpus processing algorithm is working in the way that I want, I will be spending the next two days studying methods for prediction, smoothing and the evaluation of the results.  It is my intention to have a working prediction program shortly.
